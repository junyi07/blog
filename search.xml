<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World</title>
    <url>/blog/2020/12/27/2020-12-27-hello-world/</url>
    <content><![CDATA[<p>Hello everyone, this is my first blog and I am really excited! </p>
<a id="more"></a>
<h2 id="Say-hi"><a href="#Say-hi" class="headerlink" title="Say hi"></a>Say hi</h2><p>I guess my blog will mainly talk about programming, my thoughts and what I learned recently. It is a good habit to write things down, isn’t it? Actually I had a thought about building my own blog from long time ago, but I was too lazy lol. Now during my winter break, because of COVID-19, I got a lot of free time. I think it is time to learn something that I’m interested in and record my learning progress.</p>
<p>BTW, I am a non-native speaker, and my first language is Chinese. However, I would like to try to write my posts in English to push myself think in English. So if my words are non-native or weired, please forgive me :)</p>
<h2 id="About-blog"><a href="#About-blog" class="headerlink" title="About blog"></a>About blog</h2><p>The blog is created based on <code>Hexo + GitHub Page + hexo-theme-next</code>. the process is much more fluent than I expect (i.e. thanks for the detailed doc). I spent two days on creating the blog. The most time-consuming thing is to decide which theme I prefer and adjust the page details and animations. I did not buy a domain name because I think my blog is more like a diary to me and this is good enough.</p>
<p>That’s it. Hope this is a good start and thanks for reading my blog!</p>
]]></content>
      <categories>
        <category>Some thoughts</category>
      </categories>
      <tags>
        <tag>Thoughts</tag>
      </tags>
  </entry>
  <entry>
    <title>Elastic Compute Cloud</title>
    <url>/blog/2020/12/28/2020-12-28-Elastic-Compute-Cloud/</url>
    <content><![CDATA[<p>Amazon Elastic Compute Cloud (Amazon EC2) provides virtual machines (VM) where you can host the same kinds of applications that you might run on a traditional on-premises server. This blog is to record what I learned about EC2 recently. </p>
<a id="more"></a>

<h2 id="EC2-use-cases"><a href="#EC2-use-cases" class="headerlink" title="EC2 use cases"></a>EC2 use cases</h2><p>The use cases include Application servers, Web servers, Database servers, Game servers, Mail servers, Media servers Catalog servers, File servers, Computing servers, Proxy servers, and so on.</p>
<h2 id="Choices-for-EC2-instance-launch"><a href="#Choices-for-EC2-instance-launch" class="headerlink" title="Choices for EC2 instance launch"></a>Choices for EC2 instance launch</h2><p>It includes AMI, Instance type, Network settings, IAM role, User data, Storage options, Tags, Security group, and Key pair.</p>
<h3 id="AMI"><a href="#AMI" class="headerlink" title="AMI"></a>AMI</h3><p>An Amazon Machine Image (AMI) provides information that is required to launch an EC2 instance (i.e. a virtual machine that runs in the AWS Cloud). You must specify a source AMI when you launch an  instance. AMI contains a Windows or Linux OS. It also often has some software pre-installed.</p>
<p>An AMI is created from an EC2 instance. Details are shown below.</p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201228181730.png"></p>
<h3 id="Instance-Type"><a href="#Instance-Type" class="headerlink" title="Instance Type"></a>Instance Type</h3><p>The instance type that you choose determines - Memoery (RAM), Prcessing power (CPU), Disk space and disk type (Storage), and Network performance</p>
<p>EC2 instance type naming and sizes: (Of course large size costs more money)</p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201228182758.png"></p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201228182843.png"></p>
<p>T3 instances: Use cases include websites and web applications, development environments, build servers, code repositories, microservices, test and staging environments, and line-of-business applications.</p>
<p>C5 instances: Use cases include scientific modeling, batch processing, ad serving, highly scalable multiplayer gaming, and video encoding.</p>
<p>R5 instances: Use cases include high-performance databases, data mining and analysis, in-memory databases, distributed web-scale in-memory caches, applications that perform real-time processing of unstructured big data, Apache Hadoop or Apache Spark clusters, and other enterprise applications</p>
<h3 id="Specify-network-settings"><a href="#Specify-network-settings" class="headerlink" title="Specify network settings"></a>Specify network settings</h3><p>After you have chosen an AMI and an instance type, you must specify the network location where the EC2 instance will be deployed.</p>
<p>When you launch an instance in a default VPC (i.e. you do not specify a VPC for the instance), AWS will assign it a public IP addressby default. When you launch an instance into a nondefault VPC (you got one), the subnet has an attribute that determines whether instances launched into that subnet receive a public IP address from the public IPv4 address pool.</p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201228183332.png"></p>
<h3 id="Attach-IAM-role"><a href="#Attach-IAM-role" class="headerlink" title="Attach IAM role"></a>Attach IAM role</h3><p>It is common to use EC2 instances to run an application that must make secure API calls to other AWS services. To support these use cases, AWS enables you to attach an AWS Identity and Access Management (IAM) role to an EC2 instance</p>
<p>Note that you should never store AWS credentials on an EC2 instance. It is highly insecure. Instead, attach an IAM role to theEC2 instance. Also, note that IAM roles are used for short-term credentials and IAM group is used for permanent credentials.</p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201228183706.png"></p>
<h3 id="Storage-options"><a href="#Storage-options" class="headerlink" title="Storage options"></a>Storage options</h3><p>Amazon Elastic Block Store (Amazon EBS) is an easy-to-use, high-performance <code>durable block storage</code> service that is designed to be used with Amazon EC2 for both throughput- and transaction-intensive workloads. </p>
<p>Amazon EC2 Instance Store provides <code>ephemeral, or temporary</code>, block-level stora ge for your instance. This storage is located on disks that are physically attached to the host computer. Instance Store works well when you must temporarily store information that changes frequently, such as buffers, caches, scratch data, and other temporary content.</p>
<p>Amazon Elastic File System (Amazon EFS) provides a simple, scalable, fully managed elastic Network File System (NFS) file system for use with AWS Cloud services and on-premises resources. It is built to scale on-demand to petabytes without disrupting applications. It grows and shrinks automatically as you add and remove files, which reduces the need to provision and manage capacity to accommodate growth.</p>
<p>Amazon Simple Storage Service (Amazon S3) is an object storage service that offers scalability, data availability, security, and performance. </p>
<h3 id="Tags"><a href="#Tags" class="headerlink" title="Tags"></a>Tags</h3><p>A tag is a label that you assign to an AWS resource. Each tag consists of a key and an optional value, both of which you define. Tags enable you to categorize AWS resources, such as EC2 instances, in different ways. For example, you might tag instances by purpose, owner, or environment. Tagging is how you can attach metadata to an EC2 instance. </p>
<h3 id="Security-group-settings"><a href="#Security-group-settings" class="headerlink" title="Security group settings"></a>Security group settings</h3><p>A security group is a set of firewall rules that control traffic to the instance.</p>
<h3 id="Create-the-key-pair"><a href="#Create-the-key-pair" class="headerlink" title="Create the key pair"></a>Create the key pair</h3><p>Amazon EC2 uses public–key cryptography to encrypt and decrypt login information. The technology uses a public key to encrypt a piece of data, and then the recipient uses the private key to decrypt the data. The public and private keys are known as a key pair. Public-key cryptography enables you to securely access your instances by using a private key instead of a password.</p>
<h3 id="Elastic-beanstalk-with-EC2"><a href="#Elastic-beanstalk-with-EC2" class="headerlink" title="Elastic beanstalk with EC2"></a>Elastic beanstalk with EC2</h3><p>When you create a web server environment, AWS Elastic Beanstalk creates one or more Amazon Elastic Compute Cloud (Amazon EC2) virtual machines, known as Instances.</p>
<p>Reference: <a href="https://aws.amazon.com/training/awsacademy/">AWS Academy</a></p>
]]></content>
      <categories>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS Storage</title>
    <url>/blog/2020/12/30/2020-12-30-AWS-Storage/</url>
    <content><![CDATA[<p>This is a summary about AWS storage - Elastic Block Store (EBS) vs Simple Storage Service (S3) vs Elastic File System (EFS).</p>
<a id="more"></a>

<h2 id="EBS"><a href="#EBS" class="headerlink" title="EBS"></a>EBS</h2><p>Amazon Elastic Block Store (EBS) enables you to create individual storage volumes and attach them to a <strong>single</strong> Amazon EC2 instance. Amazon EBS offers block-level storage, where its volumes are automatically replicated within its Availability Zone. Amazon EBS is designed to provide durable, detachable, block-level storage (which is like an external hard drive) for your Amazon EC2 instances. Because they are directly attached to the instances, they can provide low latency between where the data is stored and where it might be used on the instance. </p>
<p>A backup of an Amazon EBS volume is called a <strong>snapshot</strong>. The first snapshot is called the baseline snapshot. Any other snapshot after the baseline captures only what is different from the previous snapshot. </p>
<p>What happens if you want to change one character in a 1-GB file? With block storage, you change only the block that contains the character. With object storage, the entire file must be updated. </p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/image-20201230182426177.png"></p>
<h3 id="Use-cases"><a href="#Use-cases" class="headerlink" title="Use cases"></a>Use cases</h3><p>You can use Amazon EBS volumes as primary storage for data that requires frequent updates, such as the system drive for an instance or storage for a database application (NoSQL or Relational db). </p>
<h2 id="S3"><a href="#S3" class="headerlink" title="S3"></a>S3</h2><p>Companies need the ability to simply and securely collect, store, and analyze their data on a massive scale. Amazon Simple Storage Service (S3) is object storage that is built to store and retrieve any amount of data from anywhere: websites and mobile apps, corporate applications, and data from Internet of Things (IoT) sensors or devices.</p>
<p>Amazon S3 is <strong>object-level storage</strong>, which means that if you want to change a part of a file, you must make the change and then re-upload the entire modified file. Amazon S3 stores data as objects within resources that are called <strong>buckets</strong>.</p>
<p>The data that you store in Amazon S3 is not associated with any particular server, and you do not need manage any infrastructure yourself. You can put as many objects into Amazon S3 as you want. Objects can be almost any data file, such as images, videos, server logs, or test data.</p>
<h3 id="Amazon-S3-storage-classes"><a href="#Amazon-S3-storage-classes" class="headerlink" title="Amazon S3 storage classes"></a>Amazon S3 storage classes</h3><p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/image-20201230183435976.png"></p>
<p>When you create a bucket in Amazon S3, it is associated with a specific AWS Region. When you store data in the bucket, it is redundantly stored across multiple AWS facilities within your selected Region. Amazon S3 is designed to durably store your data, even if there is concurrent data loss in two AWS facilities.</p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/image-20201230183822993.png"></p>
<h3 id="Use-cases-1"><a href="#Use-cases-1" class="headerlink" title="Use cases"></a>Use cases</h3><ul>
<li><p>Backup and storage – Provide data backup and storage services for others, such as test data</p>
</li>
<li><p>Application hosting – Provide services that deploy, install, and manage web applications</p>
</li>
<li><p>Media hosting – Build a redundant, scalable, and highly available infrastructure that hosts video, photo, or music uploads and downloads</p>
</li>
<li><p>Software delivery – Host your software applications that customers can download.</p>
</li>
</ul>
<p>As a location for any application data, Amazon S3 buckets provide a shared location for storing objects that any instances of your application can access—including applications on Amazon EC2 or even traditional servers. This feature can be useful for user-generated media files, server logs, or other files that your application must store in a common location. Also, because the content can be fetched directly over the internet, you can offload serving that content from your application and enable clients to directly fetch the data from Amazon S3 themselves. </p>
<p>For static web hosting, Amazon S3 buckets can serve the static contents of your website, including HTML, CSS, JavaScript, and other files. </p>
<p>The high durability of Amazon S3 makes it a good candidate for storing backups of your data. For greater availability and disaster recovery capability, Amazon S3 can even be configured to support cross-Region replication so that data in an Amazon S3 bucket in one Region can be automatically replicated to another Amazon S3 Region.</p>
<h3 id="S3-vs-S3-Glacier"><a href="#S3-vs-S3-Glacier" class="headerlink" title="S3 vs S3 Glacier"></a>S3 vs S3 Glacier</h3><ul>
<li><p>Amazon S3 is designed for frequent, low-latency access to your data, but Amazon S3 Glacier is designed for low-cost, long-term storage of infrequently accessed data.</p>
</li>
<li><p>The maximum item size in Amazon S3 is 5 TB, but Amazon S3 Glacier can store items that are up to 40 TB.</p>
</li>
<li><p>Because Amazon S3 gives you faster access to your data, the storage cost per gigabyte is higher than it is with Amazon S3 Glacier. </p>
</li>
<li><p>While both services have per-request charges, Amazon S3 charges for PUT, COPY, POST, LIST, GET operations. In contrast, Amazon S3 Glacier charges for UPLOAD and retrieval operations.</p>
</li>
<li><p>Because Amazon S3 Glacier was designed for less-frequent access to data, it costs more for each retrieval request than Amazon S3. </p>
</li>
</ul>
<h2 id="EFS"><a href="#EFS" class="headerlink" title="EFS"></a>EFS</h2><p>Amazon Elastic File System (Amazon EFS) is a fully managed service that makes it easy to set up and scale file storage in the AWS Cloud. Amazon EFS file systems can <strong>automatically scale</strong> from gigabytes to petabytes of data without the need to provision storage. Thousands of Amazon EC2 instances can access <strong>one</strong> Amazon EFS file system at the same time, and Amazon EFS is designed to provide consistent performance to each Amazon EC2 instance. Amazon EC2 instances that run in multiple Availability Zones within the same AWS Region can access the file system, so many users can access and share a common data source.</p>
<p>Mount target: To access your file system, you must create mount targets in your VPC. </p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/image-20201230190700084.png"></p>
<h3 id="Use-cases-2"><a href="#Use-cases-2" class="headerlink" title="Use cases"></a>Use cases</h3><p>big data and analytics, media processing workflows, content management, web serving, and home directories. </p>
<h3 id="Key-points"><a href="#Key-points" class="headerlink" title="Key points"></a>Key points</h3><ul>
<li>Amazon EFS provides file storage over a network.</li>
<li>Perfect for big data and analytics, media processing workflows content management, web serving, and home directories.</li>
<li>Fully managed service that eliminates storage administration tasks</li>
<li>Accessible from the console, an API, or the CLI.</li>
<li>Scales up or down as files are added or removed and you pay for what you use.</li>
</ul>
<p>Reference: <a href="https://aws.amazon.com/training/awsacademy/">AWS Academy</a></p>
]]></content>
      <categories>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS Database</title>
    <url>/blog/2020/12/31/2020-12-31-AWS-Database/</url>
    <content><![CDATA[<p>This post is talking about Amazon Relational Database Service (RDS), Amazon DynamoDB, Amazon Redshift, and Amazon Aurora.</p>
<a id="more"></a>

<h2 id="Unmanaged-vs-managed-services"><a href="#Unmanaged-vs-managed-services" class="headerlink" title="Unmanaged vs managed services"></a>Unmanaged vs managed services</h2><p>AWS solutions typically fall into one of two categories: unmanaged or managed.</p>
<h3 id="Unmanaged-services"><a href="#Unmanaged-services" class="headerlink" title="Unmanaged services"></a>Unmanaged services</h3><p>Unmanaged services are typically provisioned in discrete portions as specified by the user.You must manage how the service responds to changes in load, errors, and situations where resources become unavailable. The benefit to using an unmanaged service is that you have more fine-tuned control over how your solution handles changes in load, errors, and situations where resources become unavailable.</p>
<p>If you move to a database that runs on an Amazon Elastic Compute Cloud (Amazon EC2) instance, you no longer need to manage the underlying hardware or handle data center operations. However, you are still responsible for patching the OS and handling all software and backup operations.</p>
<h3 id="managed-services"><a href="#managed-services" class="headerlink" title="managed services"></a>managed services</h3><p>Managed services require the user to configure them. For example, you create an Amazon Simple Storage Service (Amazon S3) bucket and then set permissions for it. However, managed services typically require less configuration. Say that you have a static website that you host in a cloud-based storage solution, such as Amazon S3. The static website does not have a web server. However, because Amazon S3 is a managed solution, features such as scaling, fault-tolerance, and availability would be handled automatically and internally by Amazon S3. </p>
<p>If you set up your database on Amazon RDS or Amazon Aurora, you reduce your administrative responsibilities. By moving to the cloud, you can automatically scale your database, enable high availability, manage backups,and perform patching. Thus, you can focus on what really matters most—optimizing your application.</p>
<h2 id="Amazon-RDS"><a href="#Amazon-RDS" class="headerlink" title="Amazon RDS"></a>Amazon RDS</h2><p>The basic building block of Amazon RDS is the database instance. A database instance is an isolated database environment that can contain multiple user-created databases. It can be accessed by using the same tools and applications that you use with a standalone database instance. Amazon RDS currently supports six databases: MySQL, Amazon Aurora, Microsoft SQL Server, PostgreSQL, MariaDB, and Oracle. </p>
<h3 id="RDS-in-VPC"><a href="#RDS-in-VPC" class="headerlink" title="RDS in VPC"></a>RDS in VPC</h3><p>You can run an instance by using Amazon Virtual Private Cloud (Amazon VPC). When you use a virtual private cloud (VPC), you have control over your virtual networking environment. </p>
<p>You can select your own IP address range, create subnets, and configure routing and access control lists (ACLs). The basic functionality of Amazon RDS is the same whether or not it runs in a VPC. Usually, the database instance is isolated in a private subnet and is only made directly accessible to indicated application instances. Subnets in a VPC are associated with a single Availability Zone, so when you select the subnet, you are also choosing the Availability Zone (or physical location) for your database instance. </p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201231123050.png"></p>
<h3 id="High-availbilty-with-Muti-AZ-deployment"><a href="#High-availbilty-with-Muti-AZ-deployment" class="headerlink" title="High availbilty with Muti-AZ deployment"></a>High availbilty with Muti-AZ deployment</h3><p>One of the most powerful features of Amazon RDS is the ability to configure your database instance for high availability with a Multi-AZ deployment. After a Multi-AZ deployment is configured, Amazon RDS automatically generates a standby copy of the database instance in another Availability Zone within the same VPC. After seeding the database copy, transactions are synchronously replicated to the standby copy. Running a database instance in a Multi-AZdeployment can enhance availability during planned system maintenance, and it can help protect your databases against database instance failure and Availability Zone disruption. </p>
<p>Therefore, if the main database instance fails in a Multi-AZ deployment, Amazon RDS automatically brings the standby database instance online as the new main instance. The synchronous replication minimizes the potential for data loss. Because your applications reference the database by name by using the Amazon RDS Domain Name System (DNS) endpoint, you don’t need to change anything in your application code to use the standby copy for failover, which means the only change is the IP address.</p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201231123227.png"></p>
<h3 id="RDS-read-replicas"><a href="#RDS-read-replicas" class="headerlink" title="RDS read replicas"></a>RDS read replicas</h3><p>Amazon RDS also supports the creation of read replicas for MySQL, MariaDB, PostgreSQL, and Amazon Aurora. Updates that are made to the source database instance are asynchronously copied to the read replica instance. You can reduce the load on your source database instance by routing read queries from your applications to the read replica. Using read replicas, you can also scale out beyond the capacity constraints of a single database instance for read-heavy database workloads. Read replicas can also be promoted to become the primary database instance, but this requires manual action because of asynchronous replication. </p>
<p>Read replicas can be created in a different Region than the primary database. This feature can help satisfy disaster recovery requirements or reduce latency by directing reads to a read replica that is closer to the user. </p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201231123514.png"></p>
<h3 id="Use-cases"><a href="#Use-cases" class="headerlink" title="Use cases"></a>Use cases</h3><ul>
<li><p>Amazon RDS works well for web and mobile applications that need a database with high throughput, massive storage scalability, and high availability. Because Amazon RDS does not have any licensing constraints, it fits the variable usage pattern of these applications. </p>
</li>
<li><p>For small and large ecommerce businesses, Amazon RDS provides a flexible, secure, and low-cost database solution for online sales and retailing. </p>
</li>
<li><p>Mobile and online games require a database platform with high throughput and availability. Amazon RDS manages the database infrastructure, so game developers do not need to worry about provisioning, scaling, or monitoring database servers. </p>
</li>
</ul>
<h3 id="When-to-use-RDS"><a href="#When-to-use-RDS" class="headerlink" title="When to use RDS"></a>When to use RDS</h3><p>Use Amazon RDS when your application requires: </p>
<ul>
<li><p>Complex transactions or complex queries</p>
</li>
<li><p>A medium to high query or write rate – up to 30,000 IOPS (15,000 reads + 15,000 writes)</p>
</li>
<li><p>No more than a single worker node or shard</p>
</li>
<li><p>High durability</p>
</li>
</ul>
<p>Do not use Amazon RDS when your application requires:</p>
<ul>
<li><p>Massive read/write rates (for example 150,000 writes per second)</p>
</li>
<li><p>Sharding due to high data size or throughput demands </p>
</li>
<li><p>Simple GET or PUT requests and queries that a NoSQL database can handle</p>
</li>
<li><p>Or, relational database management system (RDBMS) customization</p>
</li>
</ul>
<p>For circumstances when you should not use Amazon RDS, consider either using a NoSQL database solution (such as DynamoDB) or running your relational database engine on Amazon EC2 instances (RDBMS) instead of Amazon RDS (which will provide you with more options for customizing your database).</p>
<h3 id="RDS-vs-EC2-vs-EBS"><a href="#RDS-vs-EC2-vs-EBS" class="headerlink" title="RDS vs EC2 vs EBS"></a>RDS vs EC2 vs EBS</h3><p>When managing your own database software directly on Amazon EC2, you should also consider the availability of fault-tolerant and persistent storage. For this purpose, we recommend that databases running on Amazon EC2 use Amazon EBS volumes, which are similar to network-attached storage. For EC2 instances running a database, you should place all database data and logs on EBS volumes. These will remain available even if the database host fails. This configuration allows for a simple failover scenario, in which a new EC2 instance can be launched if a host fails, and the existing EBS volumes can be attached to the new instance. The database can then pick up where it left off.</p>
<ul>
<li><p>EBS - traditional disk storage</p>
</li>
<li><p>EC2 - a server VM that can use EBS volumes for its disks. you can install a DB on this and administer it completely yourself.</p>
</li>
<li><p>RDS - AWS will spin up the required EC2 instances and attach EBS volumes etc and do most of the low level DB management for you</p>
</li>
</ul>
<h2 id="Amazon-DynamoDB"><a href="#Amazon-DynamoDB" class="headerlink" title="Amazon DynamoDB"></a>Amazon DynamoDB</h2><p>DynamoDB is a fast and flexible NoSQL database service for all applications that need consistent, single-digit-millisecond latency at any scale. One of the benefits of a NoSQL database is that items in the same table can have different attributes. </p>
<h3 id="DynamoDB-components"><a href="#DynamoDB-components" class="headerlink" title="DynamoDB components"></a>DynamoDB components</h3><ul>
<li><p>A table is a collection of data.</p>
</li>
<li><p>Items are a group of attributes that is uniquely identifiable among all the other items.</p>
</li>
<li><p>Attributes are a fundamental data element, something that does not need to be broken down any further.</p>
</li>
</ul>
<h3 id="Primary-key-in-DynamoDB"><a href="#Primary-key-in-DynamoDB" class="headerlink" title="Primary key in DynamoDB"></a>Primary key in DynamoDB</h3><ul>
<li><p>In the first method, the query operation takes advantage of partitioning to effectively locate items by using the primary key. </p>
</li>
<li><p>The second method is via a scan, which enables you to locate items in the table by matching conditions on non-key attributes. The second method gives you the flexibility to locate items by other attributes. However, the operation is less efficient because DynamoDB will scan through all the items in the table to find the ones that match your criteria. </p>
</li>
</ul>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201231182808.png"></p>
<h2 id="Amazon-Redshift"><a href="#Amazon-Redshift" class="headerlink" title="Amazon Redshift"></a>Amazon Redshift</h2><p>Amazon Redshift is a fast and powerful, fully managed <strong>data warehouse</strong> that is simple and cost-effective to set up, use, and scale. It enables you to run complex analytic queries against petabytes of structured data by using sophisticated query optimization, columnar storage on high-performance local disks, and massively parallel data processing. Most results come back in seconds.</p>
<h3 id="Parallel-processing-architecture"><a href="#Parallel-processing-architecture" class="headerlink" title="Parallel processing architecture"></a>Parallel processing architecture</h3><p>The leader node manages communications with client programs and all communication with compute nodes. It parses and develops plans to carry out database operations—specifically, the series of steps that are needed to obtain results for complex queries. The leader node compiles code for individual elements of the plan and assigns the code to individual compute nodes. The compute nodes run the compiled code and send intermediate results back to the leader node for final aggregation.</p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201231185253.png"></p>
<h3 id="Use-cases-1"><a href="#Use-cases-1" class="headerlink" title="Use cases"></a>Use cases</h3><ul>
<li>Enterprise data warehouse (EDW). Many customers migrate their traditional enterprise data warehouses to Amazon Redshift with the primary goal of agility. Customers can start at whatever scale they want and experiment with their data without needing to rely on complicated processes with their IT departments to procure and prepare their software.</li>
<li>Big data customers have one thing in common: massive amounts of data that stretch their existing systems to a breaking point. Smaller customers might not have the resources toprocure the hardware and expertise that is needed to run these systems. With Amazon Redshift, smaller customers can quickly set up and use a data warehouse at a comparatively low price point.</li>
<li>Software as a service (SaaS) customers can take advantage of the scalable, easy-to-manage features that Amazon Redshift provides. Some customers use the Amazon Redshift to provide analytic capabilities to their applications. Some users deploy a cluster per customer,and use tagging to simplify and manage their service level agreements (SLAs) and billing. Amazon Redshift can help you reduce hardware and software costs. </li>
</ul>
<h2 id="Amazon-Aurora"><a href="#Amazon-Aurora" class="headerlink" title="Amazon Aurora"></a>Amazon Aurora</h2><p>Amazon Aurora is a MySQL- and PostgreSQL-compatible relational database that is built for the cloud. Why might you use Amazon Aurora over other options, like SQL with Amazon RDS? Most of that decision involves the high availability and resilient design that Amazon Aurora offers.</p>
<p>Amazon Aurora is designed to be <strong>highly available</strong>: itstores multiple copies of your data across multiple Availability Zones with continuous backups to Amazon S3. Amazon Aurora can use up to 15 read replicas can be used to reduce the possibility of losing your data. Additionally, Amazon Aurora is designed for instant crash recovery if your primary database becomes unhealthy.</p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201231205925.png"></p>
<p>After a database crash, Amazon Aurora does not need to replay the redo log from the last database checkpoint. Instead, it performs this on every read operation. This reduces the restart time after a database crash to less than 60 seconds in most cases.</p>
<p>With Amazon Aurora, the buffer cache is moved out of the database process, which makes it available immediately at restart. This reduces the need for you to throttle access until the cache is repopulated to avoid brownouts.</p>
<p>Reference: <a href="https://aws.amazon.com/training/awsacademy/">AWS Academy</a></p>
]]></content>
      <categories>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>AWS</tag>
      </tags>
  </entry>
</search>
