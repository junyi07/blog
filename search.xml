<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World</title>
    <url>/blog/2020/12/27/2020-12-27-hello-world/</url>
    <content><![CDATA[<p>Hello everyone, this is my first blog and I am really excited! </p>
<a id="more"></a>
<h2 id="Say-hi"><a href="#Say-hi" class="headerlink" title="Say hi"></a>Say hi</h2><p>I guess my blog will mainly talk about programming, my thoughts and what I learned recently. It is a good habit to write things down, isn’t it? Actually I had a thought about building my own blog from long time ago, but I was too lazy lol. Now during my winter break, because of COVID-19, I got a lot of free time. I think it is time to learn something that I’m interested in and record my learning progress.</p>
<p>BTW, I am a non-native speaker, and my first language is Chinese. However, I would like to try to write my posts in English to push myself think in English. So if my words are non-native or weired, please forgive me :)</p>
<h2 id="About-blog"><a href="#About-blog" class="headerlink" title="About blog"></a>About blog</h2><p>The blog is created based on <code>Hexo + GitHub Page + hexo-theme-next</code>. the process is much more fluent than I expect (i.e. thanks for the detailed doc). I spent two days on creating the blog. The most time-consuming thing is to decide which theme I prefer and adjust the page details and animations. I did not buy a domain name because I think my blog is more like a diary to me and this is good enough.</p>
<p>That’s it. Hope this is a good start and thanks for reading my blog!</p>
]]></content>
      <categories>
        <category>Some thoughts</category>
      </categories>
      <tags>
        <tag>Thoughts</tag>
      </tags>
  </entry>
  <entry>
    <title>Elastic Compute Cloud</title>
    <url>/blog/2020/12/28/2020-12-28-Elastic-Compute-Cloud/</url>
    <content><![CDATA[<p>Amazon Elastic Compute Cloud (Amazon EC2) provides virtual machines (VM) where you can host the same kinds of applications that you might run on a traditional on-premises server. This blog is to record what I learned about EC2 recently. </p>
<a id="more"></a>

<h2 id="EC2-use-cases"><a href="#EC2-use-cases" class="headerlink" title="EC2 use cases"></a>EC2 use cases</h2><p>The use cases include Application servers, Web servers, Database servers, Game servers, Mail servers, Media servers Catalog servers, File servers, Computing servers, Proxy servers, and so on.</p>
<h2 id="Choices-for-EC2-instance-launch"><a href="#Choices-for-EC2-instance-launch" class="headerlink" title="Choices for EC2 instance launch"></a>Choices for EC2 instance launch</h2><p>It includes AMI, Instance type, Network settings, IAM role, User data, Storage options, Tags, Security group, and Key pair.</p>
<h3 id="AMI"><a href="#AMI" class="headerlink" title="AMI"></a>AMI</h3><p>An Amazon Machine Image (AMI) provides information that is required to launch an EC2 instance (i.e. a virtual machine that runs in the AWS Cloud). You must specify a source AMI when you launch an  instance. AMI contains a Windows or Linux OS. It also often has some software pre-installed.</p>
<p>An AMI is created from an EC2 instance. Details are shown below.</p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201228181730.png"></p>
<h3 id="Instance-Type"><a href="#Instance-Type" class="headerlink" title="Instance Type"></a>Instance Type</h3><p>The instance type that you choose determines - Memoery (RAM), Prcessing power (CPU), Disk space and disk type (Storage), and Network performance</p>
<p>EC2 instance type naming and sizes: (Of course large size costs more money)</p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201228182758.png"></p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201228182843.png"></p>
<p>T3 instances: Use cases include websites and web applications, development environments, build servers, code repositories, microservices, test and staging environments, and line-of-business applications.</p>
<p>C5 instances: Use cases include scientific modeling, batch processing, ad serving, highly scalable multiplayer gaming, and video encoding.</p>
<p>R5 instances: Use cases include high-performance databases, data mining and analysis, in-memory databases, distributed web-scale in-memory caches, applications that perform real-time processing of unstructured big data, Apache Hadoop or Apache Spark clusters, and other enterprise applications</p>
<h3 id="Specify-network-settings"><a href="#Specify-network-settings" class="headerlink" title="Specify network settings"></a>Specify network settings</h3><p>After you have chosen an AMI and an instance type, you must specify the network location where the EC2 instance will be deployed.</p>
<p>When you launch an instance in a default VPC (i.e. you do not specify a VPC for the instance), AWS will assign it a public IP addressby default. When you launch an instance into a nondefault VPC (you got one), the subnet has an attribute that determines whether instances launched into that subnet receive a public IP address from the public IPv4 address pool.</p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201228183332.png"></p>
<h3 id="Attach-IAM-role"><a href="#Attach-IAM-role" class="headerlink" title="Attach IAM role"></a>Attach IAM role</h3><p>It is common to use EC2 instances to run an application that must make secure API calls to other AWS services. To support these use cases, AWS enables you to attach an AWS Identity and Access Management (IAM) role to an EC2 instance</p>
<p>Note that you should never store AWS credentials on an EC2 instance. It is highly insecure. Instead, attach an IAM role to theEC2 instance. Also, note that IAM roles are used for short-term credentials and IAM group is used for permanent credentials.</p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201228183706.png"></p>
<h3 id="Storage-options"><a href="#Storage-options" class="headerlink" title="Storage options"></a>Storage options</h3><p>Amazon Elastic Block Store (Amazon EBS) is an easy-to-use, high-performance <code>durable block storage</code> service that is designed to be used with Amazon EC2 for both throughput- and transaction-intensive workloads. </p>
<p>Amazon EC2 Instance Store provides <code>ephemeral, or temporary</code>, block-level stora ge for your instance. This storage is located on disks that are physically attached to the host computer. Instance Store works well when you must temporarily store information that changes frequently, such as buffers, caches, scratch data, and other temporary content.</p>
<p>Amazon Elastic File System (Amazon EFS) provides a simple, scalable, fully managed elastic Network File System (NFS) file system for use with AWS Cloud services and on-premises resources. It is built to scale on-demand to petabytes without disrupting applications. It grows and shrinks automatically as you add and remove files, which reduces the need to provision and manage capacity to accommodate growth.</p>
<p>Amazon Simple Storage Service (Amazon S3) is an object storage service that offers scalability, data availability, security, and performance. </p>
<h3 id="Tags"><a href="#Tags" class="headerlink" title="Tags"></a>Tags</h3><p>A tag is a label that you assign to an AWS resource. Each tag consists of a key and an optional value, both of which you define. Tags enable you to categorize AWS resources, such as EC2 instances, in different ways. For example, you might tag instances by purpose, owner, or environment. Tagging is how you can attach metadata to an EC2 instance. </p>
<h3 id="Security-group-settings"><a href="#Security-group-settings" class="headerlink" title="Security group settings"></a>Security group settings</h3><p>A security group is a set of firewall rules that control traffic to the instance.</p>
<h3 id="Create-the-key-pair"><a href="#Create-the-key-pair" class="headerlink" title="Create the key pair"></a>Create the key pair</h3><p>Amazon EC2 uses public–key cryptography to encrypt and decrypt login information. The technology uses a public key to encrypt a piece of data, and then the recipient uses the private key to decrypt the data. The public and private keys are known as a key pair. Public-key cryptography enables you to securely access your instances by using a private key instead of a password.</p>
<h3 id="Elastic-beanstalk-with-EC2"><a href="#Elastic-beanstalk-with-EC2" class="headerlink" title="Elastic beanstalk with EC2"></a>Elastic beanstalk with EC2</h3><p>When you create a web server environment, AWS Elastic Beanstalk creates one or more Amazon Elastic Compute Cloud (Amazon EC2) virtual machines, known as Instances.</p>
<p>Reference: <a href="https://aws.amazon.com/training/awsacademy/">AWS Academy</a></p>
]]></content>
      <categories>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS Storage</title>
    <url>/blog/2020/12/30/2020-12-30-AWS-Storage/</url>
    <content><![CDATA[<p>This is a summary about AWS storage - Elastic Block Store (EBS) vs Simple Storage Service (S3) vs Elastic File System (EFS).</p>
<a id="more"></a>

<h2 id="EBS"><a href="#EBS" class="headerlink" title="EBS"></a>EBS</h2><p>Amazon Elastic Block Store (EBS) enables you to create individual storage volumes and attach them to a <strong>single</strong> Amazon EC2 instance. Amazon EBS offers block-level storage, where its volumes are automatically replicated within its Availability Zone. Amazon EBS is designed to provide durable, detachable, block-level storage (which is like an external hard drive) for your Amazon EC2 instances. Because they are directly attached to the instances, they can provide low latency between where the data is stored and where it might be used on the instance. </p>
<p>A backup of an Amazon EBS volume is called a <strong>snapshot</strong>. The first snapshot is called the baseline snapshot. Any other snapshot after the baseline captures only what is different from the previous snapshot. </p>
<p>What happens if you want to change one character in a 1-GB file? With block storage, you change only the block that contains the character. With object storage, the entire file must be updated. </p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/image-20201230182426177.png"></p>
<h3 id="Use-cases"><a href="#Use-cases" class="headerlink" title="Use cases"></a>Use cases</h3><p>You can use Amazon EBS volumes as primary storage for data that requires frequent updates, such as the system drive for an instance or storage for a database application (NoSQL or Relational db). </p>
<h2 id="S3"><a href="#S3" class="headerlink" title="S3"></a>S3</h2><p>Companies need the ability to simply and securely collect, store, and analyze their data on a massive scale. Amazon Simple Storage Service (S3) is object storage that is built to store and retrieve any amount of data from anywhere: websites and mobile apps, corporate applications, and data from Internet of Things (IoT) sensors or devices.</p>
<p>Amazon S3 is <strong>object-level storage</strong>, which means that if you want to change a part of a file, you must make the change and then re-upload the entire modified file. Amazon S3 stores data as objects within resources that are called <strong>buckets</strong>.</p>
<p>The data that you store in Amazon S3 is not associated with any particular server, and you do not need manage any infrastructure yourself. You can put as many objects into Amazon S3 as you want. Objects can be almost any data file, such as images, videos, server logs, or test data.</p>
<h3 id="Amazon-S3-storage-classes"><a href="#Amazon-S3-storage-classes" class="headerlink" title="Amazon S3 storage classes"></a>Amazon S3 storage classes</h3><p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/image-20201230183435976.png"></p>
<p>When you create a bucket in Amazon S3, it is associated with a specific AWS Region. When you store data in the bucket, it is redundantly stored across multiple AWS facilities within your selected Region. Amazon S3 is designed to durably store your data, even if there is concurrent data loss in two AWS facilities.</p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/image-20201230183822993.png"></p>
<h3 id="Use-cases-1"><a href="#Use-cases-1" class="headerlink" title="Use cases"></a>Use cases</h3><ul>
<li><p>Backup and storage – Provide data backup and storage services for others, such as test data</p>
</li>
<li><p>Application hosting – Provide services that deploy, install, and manage web applications</p>
</li>
<li><p>Media hosting – Build a redundant, scalable, and highly available infrastructure that hosts video, photo, or music uploads and downloads</p>
</li>
<li><p>Software delivery – Host your software applications that customers can download.</p>
</li>
</ul>
<p>As a location for any application data, Amazon S3 buckets provide a shared location for storing objects that any instances of your application can access—including applications on Amazon EC2 or even traditional servers. This feature can be useful for user-generated media files, server logs, or other files that your application must store in a common location. Also, because the content can be fetched directly over the internet, you can offload serving that content from your application and enable clients to directly fetch the data from Amazon S3 themselves. </p>
<p>For static web hosting, Amazon S3 buckets can serve the static contents of your website, including HTML, CSS, JavaScript, and other files. </p>
<p>The high durability of Amazon S3 makes it a good candidate for storing backups of your data. For greater availability and disaster recovery capability, Amazon S3 can even be configured to support cross-Region replication so that data in an Amazon S3 bucket in one Region can be automatically replicated to another Amazon S3 Region.</p>
<h3 id="S3-vs-S3-Glacier"><a href="#S3-vs-S3-Glacier" class="headerlink" title="S3 vs S3 Glacier"></a>S3 vs S3 Glacier</h3><ul>
<li><p>Amazon S3 is designed for frequent, low-latency access to your data, but Amazon S3 Glacier is designed for low-cost, long-term storage of infrequently accessed data.</p>
</li>
<li><p>The maximum item size in Amazon S3 is 5 TB, but Amazon S3 Glacier can store items that are up to 40 TB.</p>
</li>
<li><p>Because Amazon S3 gives you faster access to your data, the storage cost per gigabyte is higher than it is with Amazon S3 Glacier. </p>
</li>
<li><p>While both services have per-request charges, Amazon S3 charges for PUT, COPY, POST, LIST, GET operations. In contrast, Amazon S3 Glacier charges for UPLOAD and retrieval operations.</p>
</li>
<li><p>Because Amazon S3 Glacier was designed for less-frequent access to data, it costs more for each retrieval request than Amazon S3. </p>
</li>
</ul>
<h2 id="EFS"><a href="#EFS" class="headerlink" title="EFS"></a>EFS</h2><p>Amazon Elastic File System (Amazon EFS) is a fully managed service that makes it easy to set up and scale file storage in the AWS Cloud. Amazon EFS file systems can <strong>automatically scale</strong> from gigabytes to petabytes of data without the need to provision storage. Thousands of Amazon EC2 instances can access <strong>one</strong> Amazon EFS file system at the same time, and Amazon EFS is designed to provide consistent performance to each Amazon EC2 instance. Amazon EC2 instances that run in multiple Availability Zones within the same AWS Region can access the file system, so many users can access and share a common data source.</p>
<p>Mount target: To access your file system, you must create mount targets in your VPC. </p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/image-20201230190700084.png"></p>
<h3 id="Use-cases-2"><a href="#Use-cases-2" class="headerlink" title="Use cases"></a>Use cases</h3><p>big data and analytics, media processing workflows, content management, web serving, and home directories. </p>
<h3 id="Key-points"><a href="#Key-points" class="headerlink" title="Key points"></a>Key points</h3><ul>
<li>Amazon EFS provides file storage over a network.</li>
<li>Perfect for big data and analytics, media processing workflows content management, web serving, and home directories.</li>
<li>Fully managed service that eliminates storage administration tasks</li>
<li>Accessible from the console, an API, or the CLI.</li>
<li>Scales up or down as files are added or removed and you pay for what you use.</li>
</ul>
<p>Reference: <a href="https://aws.amazon.com/training/awsacademy/">AWS Academy</a></p>
]]></content>
      <categories>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS Database</title>
    <url>/blog/2020/12/31/2020-12-31-AWS-Database/</url>
    <content><![CDATA[<p>This post is talking about Amazon Relational Database Service (RDS), Amazon DynamoDB, Amazon Redshift, and Amazon Aurora.</p>
<a id="more"></a>

<h2 id="Unmanaged-vs-managed-services"><a href="#Unmanaged-vs-managed-services" class="headerlink" title="Unmanaged vs managed services"></a>Unmanaged vs managed services</h2><p>AWS solutions typically fall into one of two categories: unmanaged or managed.</p>
<h3 id="Unmanaged-services"><a href="#Unmanaged-services" class="headerlink" title="Unmanaged services"></a>Unmanaged services</h3><p>Unmanaged services are typically provisioned in discrete portions as specified by the user.You must manage how the service responds to changes in load, errors, and situations where resources become unavailable. The benefit to using an unmanaged service is that you have more fine-tuned control over how your solution handles changes in load, errors, and situations where resources become unavailable.</p>
<p>If you move to a database that runs on an Amazon Elastic Compute Cloud (Amazon EC2) instance, you no longer need to manage the underlying hardware or handle data center operations. However, you are still responsible for patching the OS and handling all software and backup operations.</p>
<h3 id="managed-services"><a href="#managed-services" class="headerlink" title="managed services"></a>managed services</h3><p>Managed services require the user to configure them. For example, you create an Amazon Simple Storage Service (Amazon S3) bucket and then set permissions for it. However, managed services typically require less configuration. Say that you have a static website that you host in a cloud-based storage solution, such as Amazon S3. The static website does not have a web server. However, because Amazon S3 is a managed solution, features such as scaling, fault-tolerance, and availability would be handled automatically and internally by Amazon S3. </p>
<p>If you set up your database on Amazon RDS or Amazon Aurora, you reduce your administrative responsibilities. By moving to the cloud, you can automatically scale your database, enable high availability, manage backups,and perform patching. Thus, you can focus on what really matters most—optimizing your application.</p>
<h2 id="Amazon-RDS"><a href="#Amazon-RDS" class="headerlink" title="Amazon RDS"></a>Amazon RDS</h2><p>The basic building block of Amazon RDS is the database instance. A database instance is an isolated database environment that can contain multiple user-created databases. It can be accessed by using the same tools and applications that you use with a standalone database instance. Amazon RDS currently supports six databases: MySQL, Amazon Aurora, Microsoft SQL Server, PostgreSQL, MariaDB, and Oracle. </p>
<h3 id="RDS-in-VPC"><a href="#RDS-in-VPC" class="headerlink" title="RDS in VPC"></a>RDS in VPC</h3><p>You can run an instance by using Amazon Virtual Private Cloud (Amazon VPC). When you use a virtual private cloud (VPC), you have control over your virtual networking environment. </p>
<p>You can select your own IP address range, create subnets, and configure routing and access control lists (ACLs). The basic functionality of Amazon RDS is the same whether or not it runs in a VPC. Usually, the database instance is isolated in a private subnet and is only made directly accessible to indicated application instances. Subnets in a VPC are associated with a single Availability Zone, so when you select the subnet, you are also choosing the Availability Zone (or physical location) for your database instance. </p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201231123050.png"></p>
<h3 id="High-availbilty-with-Muti-AZ-deployment"><a href="#High-availbilty-with-Muti-AZ-deployment" class="headerlink" title="High availbilty with Muti-AZ deployment"></a>High availbilty with Muti-AZ deployment</h3><p>One of the most powerful features of Amazon RDS is the ability to configure your database instance for high availability with a Multi-AZ deployment. After a Multi-AZ deployment is configured, Amazon RDS automatically generates a standby copy of the database instance in another Availability Zone within the same VPC. After seeding the database copy, transactions are synchronously replicated to the standby copy. Running a database instance in a Multi-AZdeployment can enhance availability during planned system maintenance, and it can help protect your databases against database instance failure and Availability Zone disruption. </p>
<p>Therefore, if the main database instance fails in a Multi-AZ deployment, Amazon RDS automatically brings the standby database instance online as the new main instance. The synchronous replication minimizes the potential for data loss. Because your applications reference the database by name by using the Amazon RDS Domain Name System (DNS) endpoint, you don’t need to change anything in your application code to use the standby copy for failover, which means the only change is the IP address.</p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201231123227.png"></p>
<h3 id="RDS-read-replicas"><a href="#RDS-read-replicas" class="headerlink" title="RDS read replicas"></a>RDS read replicas</h3><p>Amazon RDS also supports the creation of read replicas for MySQL, MariaDB, PostgreSQL, and Amazon Aurora. Updates that are made to the source database instance are asynchronously copied to the read replica instance. You can reduce the load on your source database instance by routing read queries from your applications to the read replica. Using read replicas, you can also scale out beyond the capacity constraints of a single database instance for read-heavy database workloads. Read replicas can also be promoted to become the primary database instance, but this requires manual action because of asynchronous replication. </p>
<p>Read replicas can be created in a different Region than the primary database. This feature can help satisfy disaster recovery requirements or reduce latency by directing reads to a read replica that is closer to the user. </p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201231123514.png"></p>
<h3 id="Use-cases"><a href="#Use-cases" class="headerlink" title="Use cases"></a>Use cases</h3><ul>
<li><p>Amazon RDS works well for web and mobile applications that need a database with high throughput, massive storage scalability, and high availability. Because Amazon RDS does not have any licensing constraints, it fits the variable usage pattern of these applications. </p>
</li>
<li><p>For small and large ecommerce businesses, Amazon RDS provides a flexible, secure, and low-cost database solution for online sales and retailing. </p>
</li>
<li><p>Mobile and online games require a database platform with high throughput and availability. Amazon RDS manages the database infrastructure, so game developers do not need to worry about provisioning, scaling, or monitoring database servers. </p>
</li>
</ul>
<h3 id="When-to-use-RDS"><a href="#When-to-use-RDS" class="headerlink" title="When to use RDS"></a>When to use RDS</h3><p>Use Amazon RDS when your application requires: </p>
<ul>
<li><p>Complex transactions or complex queries</p>
</li>
<li><p>A medium to high query or write rate – up to 30,000 IOPS (15,000 reads + 15,000 writes)</p>
</li>
<li><p>No more than a single worker node or shard</p>
</li>
<li><p>High durability</p>
</li>
</ul>
<p>Do not use Amazon RDS when your application requires:</p>
<ul>
<li><p>Massive read/write rates (for example 150,000 writes per second)</p>
</li>
<li><p>Sharding due to high data size or throughput demands </p>
</li>
<li><p>Simple GET or PUT requests and queries that a NoSQL database can handle</p>
</li>
<li><p>Or, relational database management system (RDBMS) customization</p>
</li>
</ul>
<p>For circumstances when you should not use Amazon RDS, consider either using a NoSQL database solution (such as DynamoDB) or running your relational database engine on Amazon EC2 instances (RDBMS) instead of Amazon RDS (which will provide you with more options for customizing your database).</p>
<h3 id="RDS-vs-EC2-vs-EBS"><a href="#RDS-vs-EC2-vs-EBS" class="headerlink" title="RDS vs EC2 vs EBS"></a>RDS vs EC2 vs EBS</h3><p>When managing your own database software directly on Amazon EC2, you should also consider the availability of fault-tolerant and persistent storage. For this purpose, we recommend that databases running on Amazon EC2 use Amazon EBS volumes, which are similar to network-attached storage. For EC2 instances running a database, you should place all database data and logs on EBS volumes. These will remain available even if the database host fails. This configuration allows for a simple failover scenario, in which a new EC2 instance can be launched if a host fails, and the existing EBS volumes can be attached to the new instance. The database can then pick up where it left off.</p>
<ul>
<li><p>EBS - traditional disk storage</p>
</li>
<li><p>EC2 - a server VM that can use EBS volumes for its disks. you can install a DB on this and administer it completely yourself.</p>
</li>
<li><p>RDS - AWS will spin up the required EC2 instances and attach EBS volumes etc and do most of the low level DB management for you</p>
</li>
</ul>
<h2 id="Amazon-DynamoDB"><a href="#Amazon-DynamoDB" class="headerlink" title="Amazon DynamoDB"></a>Amazon DynamoDB</h2><p>DynamoDB is a fast and flexible NoSQL database service for all applications that need consistent, single-digit-millisecond latency at any scale. One of the benefits of a NoSQL database is that items in the same table can have different attributes. </p>
<h3 id="DynamoDB-components"><a href="#DynamoDB-components" class="headerlink" title="DynamoDB components"></a>DynamoDB components</h3><ul>
<li><p>A table is a collection of data.</p>
</li>
<li><p>Items are a group of attributes that is uniquely identifiable among all the other items.</p>
</li>
<li><p>Attributes are a fundamental data element, something that does not need to be broken down any further.</p>
</li>
</ul>
<h3 id="Primary-key-in-DynamoDB"><a href="#Primary-key-in-DynamoDB" class="headerlink" title="Primary key in DynamoDB"></a>Primary key in DynamoDB</h3><ul>
<li><p>In the first method, the query operation takes advantage of partitioning to effectively locate items by using the primary key. </p>
</li>
<li><p>The second method is via a scan, which enables you to locate items in the table by matching conditions on non-key attributes. The second method gives you the flexibility to locate items by other attributes. However, the operation is less efficient because DynamoDB will scan through all the items in the table to find the ones that match your criteria. </p>
</li>
</ul>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201231182808.png"></p>
<h2 id="Amazon-Redshift"><a href="#Amazon-Redshift" class="headerlink" title="Amazon Redshift"></a>Amazon Redshift</h2><p>Amazon Redshift is a fast and powerful, fully managed <strong>data warehouse</strong> that is simple and cost-effective to set up, use, and scale. It enables you to run complex analytic queries against petabytes of structured data by using sophisticated query optimization, columnar storage on high-performance local disks, and massively parallel data processing. Most results come back in seconds.</p>
<h3 id="Parallel-processing-architecture"><a href="#Parallel-processing-architecture" class="headerlink" title="Parallel processing architecture"></a>Parallel processing architecture</h3><p>The leader node manages communications with client programs and all communication with compute nodes. It parses and develops plans to carry out database operations—specifically, the series of steps that are needed to obtain results for complex queries. The leader node compiles code for individual elements of the plan and assigns the code to individual compute nodes. The compute nodes run the compiled code and send intermediate results back to the leader node for final aggregation.</p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201231185253.png"></p>
<h3 id="Use-cases-1"><a href="#Use-cases-1" class="headerlink" title="Use cases"></a>Use cases</h3><ul>
<li>Enterprise data warehouse (EDW). Many customers migrate their traditional enterprise data warehouses to Amazon Redshift with the primary goal of agility. Customers can start at whatever scale they want and experiment with their data without needing to rely on complicated processes with their IT departments to procure and prepare their software.</li>
<li>Big data customers have one thing in common: massive amounts of data that stretch their existing systems to a breaking point. Smaller customers might not have the resources toprocure the hardware and expertise that is needed to run these systems. With Amazon Redshift, smaller customers can quickly set up and use a data warehouse at a comparatively low price point.</li>
<li>Software as a service (SaaS) customers can take advantage of the scalable, easy-to-manage features that Amazon Redshift provides. Some customers use the Amazon Redshift to provide analytic capabilities to their applications. Some users deploy a cluster per customer,and use tagging to simplify and manage their service level agreements (SLAs) and billing. Amazon Redshift can help you reduce hardware and software costs. </li>
</ul>
<h2 id="Amazon-Aurora"><a href="#Amazon-Aurora" class="headerlink" title="Amazon Aurora"></a>Amazon Aurora</h2><p>Amazon Aurora is a MySQL- and PostgreSQL-compatible relational database that is built for the cloud. Why might you use Amazon Aurora over other options, like SQL with Amazon RDS? Most of that decision involves the high availability and resilient design that Amazon Aurora offers.</p>
<p>Amazon Aurora is designed to be <strong>highly available</strong>: itstores multiple copies of your data across multiple Availability Zones with continuous backups to Amazon S3. Amazon Aurora can use up to 15 read replicas can be used to reduce the possibility of losing your data. Additionally, Amazon Aurora is designed for instant crash recovery if your primary database becomes unhealthy.</p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201231205925.png"></p>
<p>After a database crash, Amazon Aurora does not need to replay the redo log from the last database checkpoint. Instead, it performs this on every read operation. This reduces the restart time after a database crash to less than 60 seconds in most cases.</p>
<p>With Amazon Aurora, the buffer cache is moved out of the database process, which makes it available immediately at restart. This reduces the need for you to throttle access until the cache is repopulated to avoid brownouts.</p>
<p>Reference: <a href="https://aws.amazon.com/training/awsacademy/">AWS Academy</a></p>
]]></content>
      <categories>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS Auto Scaling and Monitoring</title>
    <url>/blog/2021/01/01/2021-01-01-AWS-Auto-Scaling-and-Monitoring/</url>
    <content><![CDATA[<p>This post is talking about why  auto scaling in AWS is important and how load balancers in AWS work.</p>
<a id="more"></a>

<h2 id="Elastic-Load-Balancing"><a href="#Elastic-Load-Balancing" class="headerlink" title="Elastic Load Balancing"></a>Elastic Load Balancing</h2><p>Elastic Load Balancing is an AWS service that <strong>distributes incoming application or network traffic</strong> across multiple targets—such as Amazon Elastic Compute Cloud (Amazon EC2) instances, containers, internet protocol (IP) addresses, and Lambda functions—in a single Availability Zone or across multiple Availability Zones. Elastic Load Balancing scales your load balancer as traffic to your application changes over time. It can automatically scale to most workloads. </p>
<h3 id="Types-of-load-balancers"><a href="#Types-of-load-balancers" class="headerlink" title="Types of load balancers"></a>Types of load balancers</h3><p>Elastic Load Balancing is available in three types:</p>
<ul>
<li><p>An <strong>Application</strong> Load Balancer operates at the application level (Open Systems Interconnection, or OSI, model layer 7). It routes traffic to targets—Amazon Elastic Compute Cloud (Amazon EC2) instances, containers, Internet Protocol (IP) addresses, and Lambda functions—based on the content of the request. It is ideal for advanced load balancing of Hypertext Transfer Protocol (HTTP) and Secure HTTP (HTTPS) traffic. An Application Load Balancer provides advanced request routing that is targeted at delivery of modern application architectures, including microservices and container-based applications. An Application Load Balancer simplifies and improves the security of your application by ensuring that the latest Secure Sockets Layer/Transport Layer Security (SSL/TLS) ciphers and protocols are used at all times.</p>
</li>
<li><p>A <strong>Network</strong> Load Balancer operates at the network transport level (OSI model layer 4), routing connections to targets—EC2 instances, microservices, and containers—based on IP protocol data. It works well for load balancing both Transmission Control Protocol (TCP) and User Datagram Protocol (UDP) traffic. A Network Load Balancer is capable of handling millions of requests per second while maintaining ultra-low latencies. A Network Load Balancer is optimized to handle sudden and volatile network traffic patterns.</p>
</li>
<li><p>A <strong>Classic</strong> Load Balancer provides basic load balancing across multiple EC2 instances, and it operates at both the application level and network transport level. A Classic Load Balancer supports the load balancing of applications that use HTTP, HTTPS, TCP, and SSL. The Classic Load Balancer is an older implementation.  When possible, AWS recommends that you use a dedicated Application Load Balancer or Network Load Balancer.</p>
</li>
</ul>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201231215357.png"></p>
<h3 id="How-Elsatic-Load-Balancing-works"><a href="#How-Elsatic-Load-Balancing-works" class="headerlink" title="How Elsatic Load Balancing works"></a>How Elsatic Load Balancing works</h3><p>A load balancer accepts incoming traffic from clients and routes requests to its registered targets (such as EC2 instances) in one or more Availability Zones.</p>
<p>You configure your load balancer to accept incoming traffic by specifying one or more listeners. A listener is a process that checks for connection requests. It is configured with a protocol and port number for connections from clients to the load balancer. Similarly, it is configured with a protocol and port number for connections from the load balancer to the targets.</p>
<p>You can also configure your load balancer to perform health checks, which are used to monitor the health of the registered targets so that the load balancer only sends requests to the healthy instances. When the load balancer detects an unhealthy target, it stops routing traffic to that target. It then resumes routing traffic to that target when it detects that the target is healthy again. </p>
<p>There is a key difference in how the load balancer types are configured. With Application Load Balancers and Network Load Balancers, you register targets in target groups, and route traffic to the target groups. With Classic Load Balancers, you register instances with the load balancer.</p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201231215449.png"></p>
<h3 id="Use-cases"><a href="#Use-cases" class="headerlink" title="Use cases"></a>Use cases</h3><ul>
<li><p>Achieve high availability and better fault tolerance for your applications– Elastic Load Balancing balances traffic across healthy targets in multiple Availability Zones. If one or more of your targets in a single Availability Zone are unhealthy, Elastic Load Balancing will route traffic to healthy targets in other Availability Zones. After the targets return to a healthy state, load balancing will automatically resume traffic to them.</p>
</li>
<li><p>Automatically load balance your containerized applications– With enhanced container support for Elastic Load Balancing, you can now load balance across multiple ports on the same EC2 instance. You can also take advantage of deep integration with Amazon Elastic Container Service (Amazon ECS), which provides a fully-managed container offering. You only need to register a service with a load balancer, and Amazon ECS transparently manages the registration and de-registration of Docker containers. The load balancer automatically detects the port and dynamically reconfigures itself.</p>
</li>
<li><p>Automatically scale your applications– Elastic Load Balancing works with Amazon CloudWatch and Amazon EC2 Auto Scaling to help you scale your applications to the demands of your customers. Amazon CloudWatch alarms can trigger auto scaling for your EC2 instance fleet when the latency of any one of your EC2 instances exceeds a preconfigured threshold. Amazon EC2 Auto Scaling then provisions new instances and your applications will be ready to serve the next customer request. The load balancer will register the EC2 instance and direct traffic to it as needed. </p>
</li>
<li><p>Use Elastic Load Balancing in your virtual private cloud (VPC)– You can use Elastic Load Balancing to create a public entry point into your VPC, or to route request traffic between tiers of your application within your VPC. You can assign security groups to your load balancer to control which ports are open to a list of allowed sources. Because Elastic Load Balancing works with your VPC, all your existing network access control lists (network ACLs) and routing tables continue to provide additional network controls. When you create a load balancer in your VPC, you can specify whether the load balancer is public (default) or internal. If you select internal, you do not need to have an internet gateway to reach the load balancer, and the private IP addresses of the load balancer will be used in the load balancer’s Domain Name System (DNS) record.</p>
</li>
<li><p>Enable hybrid load balancing– Elastic Load Balancing enables you to load balance across AWS and on-premises resources by using the same load balancer. For example, if you must distribute application traffic across both AWS and on-premises resources, you can register all the resources to the same target group and associate the target group with a load balancer. Alternatively, you can use DNS-based weighted load balancing across AWS and on-premises resources by using two load balancers, with one load balancer for AWS and other load balancer for on-premises resources. You can also use hybrid load balancing to benefit separate applications where one application is in a VPC and the other application is in an on-premises location. Put the VPC targets in one target group and the on-premises targets in another target group, and then use content-based routing to route traffic to each target group.</p>
</li>
<li><p>Invoking Lambda functions over HTTP(S)– Elastic Load Balancing supports invoking Lambda functions to serve HTTP(S) requests. This enables users to access serverless applications from any HTTP client, including web browsers. You can register Lambda functions as targets and use the support for content-based routing rules in Application Load Balancers to route requests to different Lambda functions. You can use an Application Load Balancer as a common HTTP endpoint for applications that use servers and serverless computing. You can build an entire website by using Lambda functions, or combine EC2 instances, containers, on-premises servers, and Lambda functions to build applications.</p>
</li>
</ul>
<h2 id="CloudWatch"><a href="#CloudWatch" class="headerlink" title="CloudWatch"></a>CloudWatch</h2><p>Amazon CloudWatch is a monitoring and observability service that is built for DevOps engineers, developers, site reliability engineers (SRE), and IT managers. CloudWatch monitors your AWS resources (and the applications that you run on AWS) in real time. You can use CloudWatch to collect and track metrics, which are variables that you can measure for your resources and applications.</p>
<h2 id="EC2-Auto-Scaling"><a href="#EC2-Auto-Scaling" class="headerlink" title="EC2 Auto Scaling"></a>EC2 Auto Scaling</h2><p>In the cloud, because computing power is a programmatic resource, you can take a flexible approach to scaling. Amazon EC2 Auto Scaling is an AWS service that helps you maintain application availability and enables you to automatically add or remove EC2 instances according to conditions you define. You can use the fleet management features of EC2 Auto Scaling to maintain the health and availability of your fleet.</p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201231223150.png"></p>
<h3 id="Auto-Scaling-groups"><a href="#Auto-Scaling-groups" class="headerlink" title="Auto Scaling groups"></a>Auto Scaling groups</h3><p>An Auto Scaling groupis a collection of Amazon EC2 instances that are treated as a logical grouping for the purposes of automatic scaling and management. The size of an Auto Scaling group depends on the number of instances you set as the desired capacity. You can adjust its size to meet demand, either manually or by using automatic scaling. </p>
<p>For example, this Auto Scaling group has a minimum size of one instance, a desired capacity of two instances, and a maximum size of four instances. The scaling policies that you define adjust the number of instances within your minimum and maximum number of instances, based on the criteria that you specify.<br><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201231224213.png"></p>
<h3 id="How-EC2-Auto-Scaling-works"><a href="#How-EC2-Auto-Scaling-works" class="headerlink" title="How EC2 Auto Scaling works"></a>How EC2 Auto Scaling works</h3><p>To launch EC2 instances, an Auto Scaling group uses a launch configuration, which is an instance configuration template. You can think of a launch configuration as whatyou are scaling. When you create a launch configuration, you specify information for the instances. The information you specify includes the ID of the Amazon Machine Image (AMI), the instance type, AWS Identity and Access Management (IAM) role, additional storage, one or more security groups, and any Amazon Elastic Block Store (Amazon EBS) volumes.</p>
<p>You define the minimum and maximum number of instances and desired capacity of your Auto Scaling group. Then, you launch it into a subnet within a VPC (you can think of this as whereyou are scaling). Amazon EC2 Auto Scaling integrates with Elastic Load Balancing to enable you to attach one or more load balancers to an existing Auto Scaling group. After you attach the load balancer, it automatically registers the instances in the group and distributes incoming traffic across the instances.</p>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201231214125.png"></p>
<ul>
<li><p>Maintain current instance levels at all times- You can configure your Auto Scaling group to maintain a specified number of running instances at all times. To maintain the current instance levels, Amazon EC2 Auto Scaling performs a periodic health check on running instances in an Auto Scaling group. When Amazon EC2 Auto Scaling finds an unhealthy instance, it terminates that instance and launches a new one.</p>
</li>
<li><p>Scheduled scaling- With scheduled scaling, scaling actions are performed automatically as a function of date and time. This is useful for predictable workloads when you know exactly when to increase or decrease the number of instances in your group. For example, say that every week, the traffic to your web application starts to increase on Wednesday, remains high on Thursday, and starts to decrease on Friday. You can plan your scaling actions based on the predictable traffic patterns of your web application. To implement scheduled scaling, you create a scheduled action</p>
</li>
<li><p>Dynamic, on-demand scaling- A more advanced way to scale your resources enables you to define parameters that control the scaling process. For example, you have a web application that currently runs on two instances and you want the CPU utilization of the Auto Scaling group to stay close to 50 percent when the load on the application changes. This option is useful for scaling in response to changing conditions, when you don’t know when those conditions will change. Dynamic scaling gives you extra capacity to handle traffic spikes without maintaining an excessive amount of idle resources. You can configure your Auto Scaling group to scale automatically to meet this need. The scaling policy typedetermines how the scaling action is performed. You can use Amazon EC2 Auto Scaling with Amazon CloudWatch to trigger the scaling policy in response to an alarm.</p>
</li>
<li><p>Predictive scaling- You can use Amazon EC2 Auto Scaling with AWS Auto Scaling to implement predictive scaling, where your capacity scales based on predicted demand. Predictive scaling uses data that is collected from your actual EC2 usage, and the data is further informed by billions of data points that are drawn from our own observations. AWS then uses well-trained machine learning models to predict your expected traffic (and EC2 usage), including daily and weekly patterns. The model needs at least 1 day of historical data to start making predictions. It is re-evaluated every 24 hours to create a forecast for the next 48 hours. The prediction process produces a scaling plan that can drive one or more groups of automatically scaled EC2 instances.</p>
</li>
</ul>
<h3 id="Implenmenting-dynamic-scaling"><a href="#Implenmenting-dynamic-scaling" class="headerlink" title="Implenmenting dynamic scaling"></a>Implenmenting dynamic scaling</h3><p>One common configuration for implementing dynamic scaling is to create a CloudWatch alarm that is based on performance information from your EC2 instances or load balancer. When a performance threshold is breached, a CloudWatch alarm triggers an automatic scaling event that either scales out or scales in EC2 instances in the Auto Scaling group. </p>
<p>To understand how it works, consider this example:</p>
<ul>
<li><p>You create an Amazon CloudWatch alarm to monitor CPU utilization across your fleet of EC2 instances and run automatic scaling policies if the average CPU utilization across the fleet goes above 60 percent for 5 minutes.</p>
</li>
<li><p>Amazon EC2 Auto Scaling instantiates a new EC2 instance into your Auto Scaling group based on the launch configuration that you create. </p>
</li>
<li><p>After the new instance is added, Amazon EC2 Auto Scaling makes a call to Elastic Load Balancing to register the new EC2 instance in that Auto Scaling group. </p>
</li>
<li><p>Elastic Load Balancing then performs the required health checks and starts distributing traffic to that instance. Elastic Load Balancing routes traffic between EC2 instances and feeds metrics to Amazon CloudWatch.</p>
</li>
</ul>
<p><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201231214454.png"><br>Amazon CloudWatch, Amazon EC2 Auto Scaling, and Elastic Load Balancing work well individually. Together, however, they become more powerful and increase the control and flexibility over how your application handles customer demand.</p>
<p>A practice diagram:<br><img src="https://junyi-blog.oss-us-east-1.aliyuncs.com/2020/20201231224652.png"></p>
<p>Reference: <a href="https://aws.amazon.com/training/awsacademy/">AWS Academy</a></p>
]]></content>
      <categories>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>AWS</tag>
      </tags>
  </entry>
  <entry>
    <title>Summary of 2020</title>
    <url>/blog/2021/01/08/2021-01-08-Summary-of-2020/</url>
    <content><![CDATA[<p>A general study summary of 2020. This year is tough, staying at home to take online courses, remote internship and so on. But there are still some good experiences to remember for me.</p>
<a id="more"></a>

<h2 id="2020-Timeline"><a href="#2020-Timeline" class="headerlink" title="2020 Timeline"></a>2020 Timeline</h2><ul>
<li><p>January: Hang out with PQ</p>
</li>
<li><p>February - April:</p>
<ol>
<li>Spring term (hybrid courses)</li>
<li>First time to be a TA for COMP 131</li>
<li>Worked on a side project <a href="https://www.cartrek.us/home">Cartrek</a> (suspended when Covid-19 outbreak..)</li>
</ol>
</li>
<li><p>May - July: Did remote Internship at Amazon and luckily got the return offer</p>
<ol>
<li>First time to worked in an all-English environment</li>
<li>Learned a lot from awesome engineers in the team</li>
</ol>
</li>
<li><p>August: Prepare for full-time job and applied for some big tech companies</p>
<ol>
<li>Got some companies OA, but got rejected by Facebook</li>
<li>Google new graduate application did not open. So accepted offer</li>
</ol>
</li>
<li><p>September - December:</p>
<ol>
<li>Fall term (online courses)</li>
<li>Worked on a side project <a href="https://luowho.com/">Luowho</a> (WeChat mini-program)</li>
<li>Worked on a side project <a href="https://offerland.ai/login">Offerland</a> (Startup)</li>
</ol>
</li>
</ul>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>This year I definitely learn a lot from my internship, side projects, and courses. Although I only had two internship experiences so far, I feel like I got a huge improvement from each internship. Back to 2019,  my first internship taught me how an industry project works. The internship at Amazon taught me how to  make use of resources and deliver results. I also learned a lot from my excellent colleagues. They let me know what a good engineer looks like. A good engineer can not only deliver results in time but also have strong ownership to the projects you own. Of course communication skills and being helpful to people are  important to a good engineer as well.</p>
<p>In addition, this year I did some side projects, which I think is precious experiences to me. My motivation is to work on some impactful projects that can benefit people’s life. In the past, I did some toy projects as well, but nobody will visit them or it is not user’s pain point. However, the projects I did this year is different. By developing <a href="https://offerland.ai/login">Offerland</a>, I learned to build a web app from scratch as well as learn Django and AWS deployment. By working on <a href="https://luowho.com/">Luowho</a>, I learned to optimize our microservice infrastructure and deploy the backend server on Tomcat. Except professional knowledge, the other thing that makes me glad is that I made some good friends who work on the same projects with me and have the same passion about programming.</p>
<p>I sincerely appreciate all help from my friends and colleagues in 2020. Hope everything would be better this year!</p>
]]></content>
  </entry>
</search>
